{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation of satellite imagery using U-Net\n",
    "## Step 1: Data preparation\n",
    "\n",
    "Based on the [tutorial by Dr. Sreenivas Bhattiprolu](https://www.youtube.com/watch?v=0W6MKZqSke8) ([Code on Github](https://github.com/bnsreenu/python_for_microscopists/tree/master/230_landcover_dataset_segmentation))\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/adrianboguszewski/landcoverai?resource=download\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1. Read large images and corresponding masks, divide them into smaller patches.\n",
    "   And write the patches as images to the local drive.\n",
    "\n",
    "2. Save only images and masks where masks have some decent amount of labels other than 0.\n",
    "   Using blank images with label=0 is a waste of time and may bias the model towards\n",
    "   unlabeled pixels.\n",
    "\n",
    "3. Divide the sorted dataset from above into train and validation datasets.\n",
    "\n",
    "4. You have to manually move some folders and rename appropriately if you want to use\n",
    "   ImageDataGenerator from keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary because of a bug https://github.com/qubvel/segmentation_models/issues/374\n",
    "%env SM_FRAMEWORK=tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import splitfolders\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "from patchify import patchify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory paths\n",
    "dir_root = Path(\"../data/landcover_ai/\")\n",
    "dir_img = Path(dir_root, \"images\")\n",
    "dir_mask = Path(dir_root, \"masks\")\n",
    "dir_patch = Path(dir_root, \"patches\")\n",
    "dir_patch_img = Path(dir_patch, \"images\")\n",
    "dir_patch_mask = Path(dir_patch, \"masks\")\n",
    "dir_patch_useful_img = Path(dir_patch, \"useful/images\")\n",
    "dir_patch_useful_mask = Path(dir_patch, \"useful/masks\")\n",
    "\n",
    "# Define file paths\n",
    "inventory_path = Path(dir_root, \"inventory.csv\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir in [\n",
    "    dir_root,\n",
    "    dir_img,\n",
    "    dir_mask,\n",
    "    dir_patch,\n",
    "    dir_patch_img,\n",
    "    dir_patch_mask,\n",
    "    dir_patch_useful_img,\n",
    "    dir_patch_useful_mask,\n",
    "]:\n",
    "    Path(dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    0: \"Not classified\",\n",
    "    1: \"Building\",\n",
    "    2: \"Woodland\",\n",
    "    3: \"Water\",\n",
    "    4: \"Roads\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths of all images\n",
    "img_files = [file for file in dir_img.iterdir()]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom colormap for mask (to get consistency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your dictionary mapping values to colors\n",
    "color_dict = {\n",
    "    0: \"white\",  # Background / Not classified\n",
    "    1: \"#E5B6BC\",  # Building\n",
    "    2: \"#C1DDC1\",  # Woodland\n",
    "    3: \"#ACD3E4\",  # Water\n",
    "    4: \"yellow\",  # Roads\n",
    "}\n",
    "\n",
    "# Colors: https://www.schemecolor.com/bleached-rainbow.php\n",
    "\n",
    "values = np.array(list(color_dict.keys()))\n",
    "colors = list(color_dict.values())\n",
    "\n",
    "# Create colormap and norm objects\n",
    "mask_cmap = ListedColormap(colors)\n",
    "mask_norm = BoundaryNorm(values, len(values))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the three RGB bands of a random image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_channels(image: Path):\n",
    "    \"\"\"\n",
    "    Function to plot an image alongside its mask.\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    img = cv2.imread(image.as_posix())  # 3 channels / spectral bands\n",
    "\n",
    "    _, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n",
    "\n",
    "    ax1.imshow(img[:, :, 0], cmap=\"Reds\")\n",
    "    ax1.set_title(\"Channel 0: Red\")\n",
    "\n",
    "    ax2.imshow(img[:, :, 1], cmap=\"Greens\")\n",
    "    ax2.set_title(\"Channel 1: Green\")\n",
    "\n",
    "    ax3.imshow(img[:, :, 2], cmap=\"Blues\")\n",
    "    ax3.set_title(\"Channel 2: Blue\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random image from all images\n",
    "img_path = np.random.choice(img_files)\n",
    "\n",
    "plot_image_channels(img_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the mask for the same image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_and_mask(image: Path):\n",
    "    \"\"\"\n",
    "    Function to plot an image alongside its mask.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image.as_posix())\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mask_path = Path(image.as_posix().replace(\"/images/\", \"/masks/\"))\n",
    "    mask = cv2.imread(mask_path.as_posix())\n",
    "\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10))\n",
    "\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title(\"RGB image\")\n",
    "\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=4)\n",
    "    cmap = plt.get_cmap(\"viridis\")\n",
    "\n",
    "    ax2.imshow(mask[:, :, 1], cmap=cmap, norm=norm)\n",
    "    ax2.set_title(\"Mask\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image with buildings\n",
    "# img_path = Path(\"data/landcover_ai/images/N-33-130-A-d-4-4.tif\")\n",
    "\n",
    "# Image with water\n",
    "# img_path = Path(\"data/landcover_ai/images/M-33-20-D-d-3-3.tif\")\n",
    "\n",
    "# Image with roads and buildings\n",
    "# img_path = Path(\"data/landcover_ai/images/M-34-6-A-d-2-2.tif\")\n",
    "\n",
    "plot_image_and_mask(img_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to define colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = Path(img_path.as_posix().replace(\"/images/\", \"/masks/\"))\n",
    "mask = cv2.imread(mask_path.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems to work, but very slow\n",
    "# https://stackoverflow.com/a/66821752\n",
    "\n",
    "data = mask[:, :, :1].squeeze().copy()\n",
    "\n",
    "# define color map\n",
    "color_map = {\n",
    "    0: np.array([255, 255, 0]),\n",
    "    1: np.array([255, 0, 0]),\n",
    "    2: np.array([0, 255, 0]),\n",
    "    3: np.array([0, 0, 255]),\n",
    "    4: np.array([255, 0, 255]),\n",
    "}\n",
    "\n",
    "# make a 3d numpy array that has a color channel dimension\n",
    "data_3d = np.ndarray(shape=(data.shape[0], data.shape[1], 3), dtype=int)\n",
    "for i in range(0, data.shape[0]):\n",
    "    for j in range(0, data.shape[1]):\n",
    "        data_3d[i][j] = color_map[data[i][j]]\n",
    "\n",
    "# display the plot\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.imshow(data_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be checked for each channel. All channels are identical\n",
    "labels, count = np.unique(mask[:, :, 0], return_counts=True)\n",
    "print(\n",
    "    f\"Labels are:\\n\\n\"\n",
    "    f\"{labels[0]}. Background: {count[0]:,} ({count[0]/np.sum(count):.2%})\\n\"\n",
    "    f\"{labels[1]}. Buildings: {count[1]:,} ({count[1]/np.sum(count):.2%})\\n\"\n",
    "    f\"{labels[2]}. Woodland: {count[2]:,} ({count[2]/np.sum(count):.2%})\\n\"\n",
    "    f\"{labels[3]}. Water: {count[3]:,} ({count[3]/np.sum(count):.2%})\\n\"\n",
    "    f\"{labels[4]}. Roads: {count[4]:,} ({count[4]/np.sum(count):.2%})\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop each large image into patches of 256x256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(\n",
    "    image_dir: Path, patch_dir: Path, filetypes: list = None, patch_size: int = 256\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Function to create patches from large images.\n",
    "    \"\"\"\n",
    "    # Set default file types\n",
    "    if filetypes is None:\n",
    "        filetypes = [\".tif\", \".tiff\"]\n",
    "\n",
    "    # Make sure patch_dir exists\n",
    "    Path(patch_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Loop through image directory\n",
    "    for file in image_dir.rglob(\"*\"):\n",
    "        if file.is_file() and file.suffix in filetypes:\n",
    "            # Read each image as BGR\n",
    "            image = cv2.imread(str(file), 1)\n",
    "\n",
    "            # Calculate nearest size divisible by patch size\n",
    "            size_x = (image.shape[1] // patch_size) * patch_size\n",
    "            size_y = (image.shape[0] // patch_size) * patch_size\n",
    "\n",
    "            # Crop image (y comes first!)\n",
    "            image = image[0:size_y, 0:size_x]\n",
    "\n",
    "            # Extract patches from each image (Step=256 for 256 patches means no overlap)\n",
    "            print(\"Patchifying image:\", file)\n",
    "            patches_img = patchify(image, (256, 256, 3), step=256)\n",
    "\n",
    "            counter_create, counter_skip = 0, 0\n",
    "\n",
    "            for i in range(patches_img.shape[0]):\n",
    "                for j in range(patches_img.shape[1]):\n",
    "                    single_patch_img = patches_img[i, j, :, :]\n",
    "\n",
    "                    # Drop extra unecessary dimension that patchify adds.\n",
    "                    single_patch_img = single_patch_img[0]\n",
    "\n",
    "                    patch_path = Path(\n",
    "                        patch_dir, f\"{file.stem}_patch_{str(i)}_{str(j)}{file.suffix}\"\n",
    "                    )\n",
    "\n",
    "                    if not patch_path.is_file():\n",
    "                        cv2.imwrite(str(patch_path), single_patch_img)\n",
    "                        counter_create += 1\n",
    "                    else:\n",
    "                        counter_skip += 1\n",
    "\n",
    "            print(f\"Created {counter_create} patches in {patch_dir}.\")\n",
    "            print(f\"Skipped {counter_skip} already existing patches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to create patches for images\n",
    "create_patches(dir_img, dir_patch_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to create patches for masks\n",
    "create_patches(dir_mask, dir_patch_mask)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot random patch alongside its mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths of all patches\n",
    "patch_files = [file for file in dir_patch_img.iterdir()]\n",
    "\n",
    "# Randomly select one of them\n",
    "patch_path = np.random.choice(img_files)\n",
    "\n",
    "plot_image_and_mask(img_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select patches containing relevant information\n",
    "\n",
    "Copy patches and masks with real information (=decent amount of labels other than 0) to a new folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_useful_patches(\n",
    "    patch_dir: Path,\n",
    "    path_useful_img: Path,\n",
    "    path_useful_mask: Path,\n",
    "    threshold: float = 0.05,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Function to select useful patches and move them to a folder.\n",
    "    Based on the percentage of classified pixels in the mask.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    for dir in [path_useful_img, path_useful_mask]:\n",
    "        Path(dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    count_useful, count_useless = 0, 0\n",
    "\n",
    "    # Loop through image directory\n",
    "    for file in patch_dir.rglob(\"*\"):\n",
    "        if file.is_file() and file.suffix in [\".tif\", \".tiff\"]:\n",
    "            mask_path = Path(file.as_posix().replace(\"/images/\", \"/masks/\"))\n",
    "            mask = cv2.imread(mask_path.as_posix(), 1)\n",
    "\n",
    "            _, counts = np.unique(mask, return_counts=True)\n",
    "\n",
    "            # Minimun percentage of useful area with labels that are not 0\n",
    "            if (counts[0] / counts.sum()) < 1 - threshold:\n",
    "                new_file_img = Path(dir_patch_useful_img, file.name)\n",
    "                file.rename(new_file_img)\n",
    "\n",
    "                new_file_mask = Path(dir_patch_useful_mask, mask_path.name)\n",
    "                mask_path.rename(new_file_mask)\n",
    "\n",
    "                count_useful += 1\n",
    "\n",
    "            else:\n",
    "                count_useless += 1\n",
    "\n",
    "    print(f\"Found {count_useful} useful images and {count_useless} useless images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_useful_patches(dir_patch_img, dir_patch_useful_img, dir_patch_useful_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create patch inventory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patch_inventory(\n",
    "    patch_dir: Path, csv_path: Path, classes: dict\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to create an inventory of classes in the patches.\n",
    "    Returns a DataFrame with infomation how often each class appears in mask patches.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create empty dataframe\n",
    "    cols = list(classes.keys()) + [\"total\"] + [f\"{str(k)}_pct\" for k in classes.keys()]\n",
    "    inventory = pd.DataFrame(columns=cols)\n",
    "\n",
    "    for file in patch_dir.iterdir():\n",
    "        mask = cv2.imread(file.as_posix(), 1)\n",
    "\n",
    "        # Count how often each class exists as pixel value\n",
    "        val, counts = np.unique(mask, return_counts=True)\n",
    "\n",
    "        # Create a dict to be added as row to the DataFrame\n",
    "        row = dict(zip(val, counts))\n",
    "        row[\"total\"] = sum(row.values())\n",
    "\n",
    "        # Calculate percentages\n",
    "        for v in val:\n",
    "            row[f\"{str(v)}_pct\"] = row[v] / row[\"total\"]\n",
    "\n",
    "        df_tmp = pd.DataFrame(row, index=[0])\n",
    "        inventory = pd.concat([inventory, df_tmp], ignore_index=True).fillna(0)\n",
    "\n",
    "    inventory.to_csv(csv_path)\n",
    "    print(f\"Saved patch inventory to {inventory_path}\")\n",
    "\n",
    "    return inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory = create_patch_inventory(dir_patch_useful_mask, inventory_path, classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training, validation and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = Path(dir_patch, \"useful\")\n",
    "output_folder = Path(dir_root, \"tmp\")\n",
    "\n",
    "for dir in [input_folder, output_folder]:\n",
    "    Path(dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Split with a ratio\n",
    "# To only split into training and validation set, set a tuple to ratio, i.e, `(.8, .2)`.\n",
    "splitfolders.ratio(\n",
    "    input_folder, output=output_folder, seed=42, ratio=(0.75, 0.25), group_prefix=None\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move files to final destination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = Path(output_folder, \"train/images/\")\n",
    "destination = Path(dir_root, \"train_images/train/\")\n",
    "\n",
    "for dir in [source, destination]:\n",
    "    Path(dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_files = {\n",
    "    \"train/images/\": \"train_images/train/\",\n",
    "    \"train/masks/\": \"train_masks/train/\",\n",
    "    \"val/images/\": \"val_images/val/\",\n",
    "    \"val/masks/\": \"val_masks/val/\",\n",
    "}\n",
    "\n",
    "for source, dest in move_files.items():\n",
    "    source = Path(output_folder, source)\n",
    "    dest = Path(dir_root, dest)\n",
    "\n",
    "    # Make sure destination exists\n",
    "    Path(dest).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for file in source.iterdir():\n",
    "        if file.is_file():\n",
    "            file.rename(Path(dest, file.name))\n",
    "            counter += 1\n",
    "\n",
    "    print(f\"Moved {counter} files from {source} to {dest}.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove temporary directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_left = 0\n",
    "\n",
    "# Count number of files left\n",
    "for file in output_folder.rglob(\"*\"):\n",
    "    if file.is_file():\n",
    "        files_left += 1\n",
    "\n",
    "if files_left == 0:\n",
    "    shutil.rmtree(output_folder)\n",
    "    print(f\"Removed empty directory {output_folder}.\")\n",
    "else:\n",
    "    print(f\"{output_folder} not empty, did not remove.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geodata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
