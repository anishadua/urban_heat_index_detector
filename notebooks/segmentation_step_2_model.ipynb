{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation of satellite imagery using U-Net\n",
    "\n",
    "## Step 2: Model building\n",
    "\n",
    "Based on the [tutorial by Dr. Sreenivas Bhattiprolu](https://www.youtube.com/watch?v=0W6MKZqSke8) ([Code on Github](https://github.com/bnsreenu/python_for_microscopists/tree/master/230_landcover_dataset_segmentation))\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/adrianboguszewski/landcoverai?resource=download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary because of a bug https://github.com/qubvel/segmentation_models/issues/374\n",
    "%env SM_FRAMEWORK=tf.keras\n",
    "\n",
    "# Add the parent directory to the path to make imports work\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import segmentation_models as sm\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from src import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case the model gets very slow, may be due to a bug in TF2.0. Uncomment this.\n",
    "# https://github.com/tensorflow/tensorflow/issues/33024\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Also check this in case you notice training to be getting increasingly slow each epoch.\n",
    "# https://stackoverflow.com/questions/53683164/keras-occupies-an-indefinitely-increasing-amount-of-memory-for-each-epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory paths\n",
    "dir_root = Path(\"..\")\n",
    "dir_data = Path(dir_root, \"data\")\n",
    "dir_data_landcover = Path(dir_data, \"landcover_ai/\")\n",
    "dir_train_img = Path(dir_data_landcover, \"train_images/train/\")\n",
    "dir_train_mask = Path(dir_data_landcover, \"train_masks/train/\")\n",
    "dir_val_img = Path(dir_data_landcover, \"val_images/val/\")\n",
    "dir_val_mask = Path(dir_data_landcover, \"val_masks/val/\")\n",
    "dir_models = Path(dir_data, \"models\")\n",
    "\n",
    "# Show how many image files exist\n",
    "for dir in [dir_train_img, dir_train_mask, dir_val_img, dir_val_mask]:\n",
    "    files = patch_files = [file for file in dir.iterdir()]\n",
    "    print(f\"{dir} has {len(files)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0: \"Not classified\", 1: \"Building\", 2: \"Woodland\", 3: \"Water\", 4: \"Roads\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize random patch alongside its mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths of all images\n",
    "img_files = [file for file in dir_train_img.iterdir()]\n",
    "\n",
    "# Get random image from all images\n",
    "img_path = np.random.choice(img_files)\n",
    "\n",
    "# Create mask path from image path\n",
    "mask_path = Path(img_path.as_posix().replace(\"/train_images/\", \"/train_masks/\"))\n",
    "\n",
    "plot.plot_image_and_mask(img_path, mask_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Generator for images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 24\n",
    "batch_size = 16  # Lower to 8 in case of memory issues\n",
    "n_classes = len(classes)\n",
    "\n",
    "# Use this to preprocess input for transfer learning\n",
    "BACKBONE = \"resnet34\"\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(img, mask, num_class):\n",
    "    \"\"\"\n",
    "    Function to perform additional preprocessing after datagen.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Scale images\n",
    "    img = scaler.fit_transform(img.reshape(-1, img.shape[-1])).reshape(img.shape)\n",
    "\n",
    "    # Preprocess based on the pretrained backbone\n",
    "    img = preprocess_input(img)\n",
    "\n",
    "    # Convert mask to one-hot\n",
    "    mask = to_categorical(mask, num_class)\n",
    "\n",
    "    return (img, mask)\n",
    "\n",
    "\n",
    "def trainGenerator(train_img_path, train_mask_path, num_class):\n",
    "    \"\"\"\n",
    "    Function to define the generator.\n",
    "    We are not doing any zoom to make sure mask values are not interpolated.\n",
    "    It is important to keep pixel values in mask as 0, 1, 2, 3, ...\n",
    "    \"\"\"\n",
    "    img_data_gen_args = dict(\n",
    "        horizontal_flip=True, vertical_flip=True, fill_mode=\"reflect\"\n",
    "    )\n",
    "\n",
    "    image_datagen = ImageDataGenerator(**img_data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**img_data_gen_args)\n",
    "\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        str(train_img_path),\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        str(train_mask_path),\n",
    "        class_mode=None,\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=batch_size,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "    for img, mask in train_generator:\n",
    "        img, mask = preprocess_data(img, mask, num_class)\n",
    "        yield (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_gen = trainGenerator(dir_train_img.parent, dir_train_mask.parent, num_class=n_classes)\n",
    "val_img_gen = trainGenerator(dir_val_img.parent, dir_val_mask.parent, num_class=n_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some images to check\n",
    "\n",
    "Make sure the generator is working and that images and masks are indeed lined up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the next batch of batch_size images\n",
    "x, y = train_img_gen.__next__()\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# Make sure x has 3 layers (RGB)\n",
    "assert x.shape[3] == 3\n",
    "\n",
    "# Make sure y has n_classes layers\n",
    "assert y.shape[3] == n_classes\n",
    "\n",
    "for i in range(0, 3):\n",
    "    image = x[i]\n",
    "    mask = np.argmax(y[i], axis=2)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = val_img_gen.__next__()\n",
    "\n",
    "print(x_val.shape, y_val.shape)\n",
    "\n",
    "# Make sure x has 3 layers (RGB)\n",
    "assert x_val.shape[3] == 3\n",
    "\n",
    "# Make sure y has n_classes layers\n",
    "assert y_val.shape[3] == n_classes\n",
    "\n",
    "for i in range(0, 3):\n",
    "    image = x_val[i]\n",
    "    mask = np.argmax(y_val[i], axis=2)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model metrics and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_imgs = len([file for file in dir_train_img.iterdir() if file.is_file()])\n",
    "num_val_images = len([file for file in dir_val_img.iterdir() if file.is_file()])\n",
    "\n",
    "steps_per_epoch = num_train_imgs // batch_size\n",
    "val_steps_per_epoch = num_val_images // batch_size\n",
    "\n",
    "IMG_HEIGHT = x.shape[1]\n",
    "IMG_WIDTH = x.shape[2]\n",
    "IMG_CHANNELS = x.shape[3]\n",
    "\n",
    "EPOCHS = 25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use transfer learning using pretrained encoder in the U-Net"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use ***Intersection over Union (IoU)*** as evaluation metric (see [here](https://towardsdatascience.com/iou-a-better-detection-evaluation-metric-45a511185be1)). is used when calculating Mean average precision (mAP). It is a number from 0 to 1 that specifies the amount of overlap between the predicted and ground truth bounding box:\n",
    "\n",
    "- an IoU of 0 means that there is no overlap between the boxes\n",
    "- an IoU of 1 means that the union of the boxes is the same as their overlap indicating that they are completely overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = sm.Unet(\n",
    "    BACKBONE,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "    classes=n_classes,\n",
    "    activation=\"softmax\",\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    \"Adam\",\n",
    "    loss=sm.losses.categorical_focal_jaccard_loss,\n",
    "    metrics=[sm.metrics.iou_score],  # Intersection over Union (IoU)\n",
    ")\n",
    "\n",
    "# Other losses to try: categorical_focal_dice_loss, cce_jaccard_loss, cce_dice_loss, categorical_focal_loss\n",
    "\n",
    "print(model.summary())\n",
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(\n",
    "    train_img_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=val_img_gen,\n",
    "    validation_steps=val_steps_per_epoch,\n",
    ")\n",
    "\n",
    "file_model = Path(\n",
    "    dir_models, f\"landcover_{EPOCHS}_epochs_{BACKBONE}_backbone_batch{batch_size}.hdf5\"\n",
    ")\n",
    "model.save(file_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training and validation IoU and loss at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, \"y\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history[\"iou_score\"]\n",
    "val_acc = history.history[\"val_iou_score\"]\n",
    "\n",
    "plt.plot(epochs, acc, \"y\", label=\"Training IoU\")\n",
    "plt.plot(epochs, val_acc, \"r\", label=\"Validation IoU\")\n",
    "plt.title(\"Training and validation IoU\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaulate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(file_model, compile=False)\n",
    "\n",
    "# Test generator using validation data.\n",
    "\n",
    "test_image_batch, test_mask_batch = val_img_gen.__next__()\n",
    "\n",
    "# Convert categorical to integer for visualization and IoU calculation\n",
    "test_mask_batch_argmax = np.argmax(test_mask_batch, axis=3)\n",
    "test_pred_batch = model.predict(test_image_batch)\n",
    "test_pred_batch_argmax = np.argmax(test_pred_batch, axis=3)\n",
    "\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)\n",
    "IOU_keras.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a few images, masks and corresponding predictions.\n",
    "img_num = random.randint(0, test_image_batch.shape[0] - 1)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title(\"Testing Image\")\n",
    "plt.imshow(test_image_batch[img_num])\n",
    "plt.subplot(232)\n",
    "plt.title(\"Testing Label\")\n",
    "plt.imshow(test_mask_batch_argmax[img_num])\n",
    "plt.subplot(233)\n",
    "plt.title(\"Prediction on test image\")\n",
    "plt.imshow(test_pred_batch_argmax[img_num])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geodata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
